import cv2
import numpy as np
import mediapipe as mp
import pyautogui
import time
from ctypes import cast, POINTER
from comtypes import CLSCTX_ALL
from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume

# Setup for volume control
devices = AudioUtilities.GetSpeakers()
interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)
volume = cast(interface, POINTER(IAudioEndpointVolume))

# Setup for face mesh
mp_face_mesh = mp.solutions.face_mesh
face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True, max_num_faces=1)
screen_w, screen_h = pyautogui.size()

# Constants
LEFT_EYE = [159, 145]
RIGHT_EYE = [386, 374]
LEFT_IRIS = 474
BLINK_THRESHOLD = 4.0  # Pixel height threshold for eye closed
CLICK_BLINK_TIME = 0.5  # max time (sec) for blink to register click
VOLUME_HOLD = 3.0  # time (sec) for 1 eye closed to start volume up
VOLUME_DOWN_HOLD = 0.8  # time (sec) for both eyes closed to start volume down

# State variables
prev_x, prev_y = 0, 0
smooth = 0.2
blink_time = 0
blink_active = False
both_eyes_close_start = 0
one_eye_close_start = 0

calibrated = False
calib_iris_x = 0
calib_iris_y = 0

cap = cv2.VideoCapture(0)

def get_eye_height(landmarks, eye_indices, h):
    top = landmarks[eye_indices[0]].y * h
    bottom = landmarks[eye_indices[1]].y * h
    return abs(bottom - top)

print("Calibration starting... Please look at the center of the screen")

# Calibration loop: average iris position for 3 seconds
calib_start_time = time.time()
calib_duration = 3
calib_positions = []

while time.time() - calib_start_time < calib_duration:
    ret, frame = cap.read()
    if not ret:
        break
    frame = cv2.flip(frame, 1)
    h, w, _ = frame.shape
    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    results = face_mesh.process(rgb)
    cv2.putText(frame, "Calibrating... Look center", (20, 50),
                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)
    if results.multi_face_landmarks:
        mesh = results.multi_face_landmarks[0].landmark
        iris = mesh[LEFT_IRIS]
        iris_x = iris.x * w
        iris_y = iris.y * h
        calib_positions.append((iris_x, iris_y))
        cv2.circle(frame, (int(iris_x), int(iris_y)), 5, (0, 255, 0), -1)
    cv2.imshow("Calibration", frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

if calib_positions:
    calib_iris_x = np.mean([p[0] for p in calib_positions])
    calib_iris_y = np.mean([p[1] for p in calib_positions])
    calibrated = True
    print("Calibration done.")
else:
    print("Calibration failed. Exiting.")
    cap.release()
    cv2.destroyAllWindows()
    exit()

# Main loop
while True:
    ret, frame = cap.read()
    if not ret:
        break
    frame = cv2.flip(frame, 1)
    h, w, _ = frame.shape
    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    results = face_mesh.process(rgb)

    current_time = time.time()
    feedback = ""

    if results.multi_face_landmarks:
        mesh = results.multi_face_landmarks[0].landmark

        left_height = get_eye_height(mesh, LEFT_EYE, h)
        right_height = get_eye_height(mesh, RIGHT_EYE, h)
        left_closed = left_height < BLINK_THRESHOLD
        right_closed = right_height < BLINK_THRESHOLD

        # Iris position and mapping to screen with calibration offset
        iris = mesh[LEFT_IRIS]
        iris_x = iris.x * w
        iris_y = iris.y * h

        # Adjust iris position relative to calibration center for better full-screen coverage
        adj_iris_x = iris_x - calib_iris_x
        adj_iris_y = iris_y - calib_iris_y

        # Map adjusted iris position to full screen (tune the multiplier for sensitivity)
        # Sensitivity factor can be tuned to improve cursor reach
        sensitivity = 3.5
        screen_x = np.clip((screen_w / 2) + adj_iris_x * sensitivity, 0, screen_w)
        screen_y = np.clip((screen_h / 2) + adj_iris_y * sensitivity, 0, screen_h)

        # Smooth cursor movement
        smooth_x = prev_x + (screen_x - prev_x) * smooth
        smooth_y = prev_y + (screen_y - prev_y) * smooth
        pyautogui.moveTo(smooth_x, smooth_y)
        prev_x, prev_y = smooth_x, smooth_y

        # CLICK: Quick blink (both eyes close & open fast)
        if left_closed and right_closed and not blink_active:
            blink_time = current_time
            blink_active = True
        elif not left_closed and not right_closed and blink_active:
            if current_time - blink_time < CLICK_BLINK_TIME:
                pyautogui.click()
                feedback = "Click"
            blink_active = False

        # VOLUME DOWN: both eyes closed continuously ≥ VOLUME_DOWN_HOLD
        if left_closed and right_closed:
            if both_eyes_close_start == 0:
                both_eyes_close_start = current_time
            elif current_time - both_eyes_close_start >= VOLUME_DOWN_HOLD:
                vol = volume.GetMasterVolumeLevelScalar()
                vol = max(vol - 0.01, 0.0)
                volume.SetMasterVolumeLevelScalar(vol, None)
                pyautogui.press("volumedown")
                feedback = "Volume Down"
        else:
            both_eyes_close_start = 0

        # VOLUME UP: exactly one eye closed continuously ≥ VOLUME_HOLD
        if left_closed != right_closed:
            if one_eye_close_start == 0:
                one_eye_close_start = current_time
            elif current_time - one_eye_close_start >= VOLUME_HOLD:
                vol = volume.GetMasterVolumeLevelScalar()
                vol = min(vol + 0.01, 1.0)
                volume.SetMasterVolumeLevelScalar(vol, None)
                pyautogui.press("volumeup")
                feedback = "Volume Up"
        else:
            one_eye_close_start = 0

        # Draw iris and feedback
        cv2.circle(frame, (int(iris_x), int(iris_y)), 5, (0, 255, 255), -1)
        if feedback:
            cv2.putText(frame, feedback, (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 2)

    else:
        # Reset timers if no face detected
        blink_active = False
        both_eyes_close_start = 0
        one_eye_close_start = 0

    frame = cv2.resize(frame, (640, 400))
    cv2.imshow("Eye Controlled System", frame)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
